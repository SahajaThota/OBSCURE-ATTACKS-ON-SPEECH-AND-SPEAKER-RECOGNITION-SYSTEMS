{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da31881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    SSA generates a trajectory matrix X from the original series y\n",
    "    by sliding a window of length dim. The trajectory matrix is aproximated\n",
    "    using SVD. The last step reconstructs the series from the aproximated trajectory matrix.\n",
    "\"\"\"\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from matplotlib import pyplot as plt\n",
    "    import pylab\n",
    "except:\n",
    "    print(\"Plotting functions will be disabled. Can't import matplotlib\")\n",
    "    pass\n",
    "\n",
    "\n",
    "def isscalar(x):\n",
    "    \"\"\"\n",
    "    Returns true if x is scalar value\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return not isinstance(x, (list, tuple, dict, np.ndarray))\n",
    "\n",
    "\n",
    "def nans(dims):\n",
    "    \"\"\"\n",
    "    nans((M,N,P,...)) is an M-by-N-by-P-by-... array of NaNs.\n",
    "    :param dims: dimensions tuple\n",
    "    :return: nans matrix\n",
    "    \"\"\"\n",
    "    return np.nan * np.ones(dims)\n",
    "\n",
    "\n",
    "def ssa(y, dim) -> tuple:\n",
    "    \"\"\"\n",
    "    Singular Spectrum Analysis decomposition for a time series\n",
    "    Example:\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>>\n",
    "    >>> x = np.linspace(0, 5, 1000)\n",
    "    >>> y = 2*x + 2*np.sin(5*x) + 0.5*np.random.randn(1000)\n",
    "    >>> pc, s, v = ssa(y, 15)\n",
    "    :param y: time series (array)\n",
    "    :param dim: the embedding dimension\n",
    "    :return: (pc, s, v) where\n",
    "             pc is the matrix with the principal components of y\n",
    "             s is the vector of the singular values of y given dim\n",
    "             v is the matrix of the singular vectors of y given dim\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    t = n - (dim - 1)\n",
    "\n",
    "    yy = linalg.hankel(y, np.zeros(dim))\n",
    "    yy = yy[:-dim + 1, :] / np.sqrt(t)\n",
    "\n",
    "    # here we use gesvd driver (as in Matlab)\n",
    "    _, s, v = linalg.svd(yy, full_matrices=False, lapack_driver='gesvd')\n",
    "\n",
    "    # find principal components\n",
    "    vt = np.matrix(v).T\n",
    "    pc = np.matrix(yy) * vt\n",
    "\n",
    "    return np.asarray(pc), s, np.asarray(vt)\n",
    "\n",
    "\n",
    "def inv_ssa(pc: np.ndarray, v: np.ndarray, k) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Series reconstruction for given SSA decomposition using vector of components\n",
    "    Example:\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> from matplotlib import pyplot as plt\n",
    "    >>> x = np.linspace(0, 5, 1000)\n",
    "    >>> y = 2*x + 2*np.sin(5*x) + 0.5*np.random.randn(1000)\n",
    "    >>> pc, s, v = ssa(y, 15)\n",
    "    >>>\n",
    "    >>> yr = inv_ssa(pc, v, [0,1])\n",
    "    >>> plt.plot(x, yr)\n",
    "    :param pc: matrix with the principal components from SSA\n",
    "    :param v: matrix of the singular vectors from SSA\n",
    "    :param k: vector with the indices of the components to be reconstructed\n",
    "    :return: the reconstructed time series\n",
    "    \"\"\"\n",
    "    if isscalar(k): k = [k]\n",
    "\n",
    "    if pc.ndim != 2:\n",
    "        raise ValueError('pc must be a 2-dimensional matrix')\n",
    "\n",
    "    if v.ndim != 2:\n",
    "        raise ValueError('v must be a 2-dimensional matrix')\n",
    "\n",
    "    t, dim = pc.shape\n",
    "    n_points = t + (dim - 1)\n",
    "\n",
    "    if any(filter(lambda x: dim < x or x < 0, k)):\n",
    "        raise ValueError('k must be vector of indexes from range 0..%d' % dim)\n",
    "\n",
    "    pc_comp = np.asarray(np.matrix(pc[:, k]) * np.matrix(v[:, k]).T)\n",
    "\n",
    "    xr = np.zeros(n_points)\n",
    "    times = np.zeros(n_points)\n",
    "\n",
    "    # reconstruction loop\n",
    "    for i in range(dim):\n",
    "        xr[i : t + i] = xr[i : t + i] + pc_comp[:, i]\n",
    "        times[i : t + i] = times[i : t + i] + 1\n",
    "\n",
    "    xr = (xr / times) * np.sqrt(t)\n",
    "    return xr\n",
    "\n",
    "\n",
    "def ssa_predict(x, dim, k, n_forecast, e=None, max_iter=10000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Series data prediction based on SSA\n",
    "    Example:\n",
    "    >>> x = np.linspace(0,5,1000)\n",
    "    >>> y = 2*x + 2*np.sin(5*x) + 0.5*np.random.randn(1000)\n",
    "    >>>\n",
    "    >>> # make prediction for next 200 points\n",
    "    >>> ys = ssa_predict(y, 100, [0,1,2], 200, 0.01)\n",
    "    >>> \n",
    "    >>> # plot prediction\n",
    "    >>> plt.figure(figsize=(16,8));\n",
    "    >>> x0 = len(y); plt.plot(range(x0), y); plt.plot(range(x0, x0 + len(ys)), ys, 'r--')\n",
    "    >>> plt.legend(['Data', 'Forecast'])\n",
    "    :param x: series to be predicted\n",
    "    :param dim: the embedding dimension\n",
    "    :param k: components indexes for reconstruction\n",
    "    :param n_forecast: number of points to forecast\n",
    "    :param e: minimum value to ensure convergence\n",
    "    :param max_iter: maximum number of iterations\n",
    "    :return: forecasted series\n",
    "    \"\"\"\n",
    "    if not e:\n",
    "        e = 0.0001 * (np.max(x) - np.min(x))\n",
    "    mean_x = x.mean()\n",
    "    x = x - mean_x\n",
    "    xf = nans(n_forecast)\n",
    "\n",
    "    for i in range(n_forecast):\n",
    "        # here we use previous value as initial estimation\n",
    "        x = np.append(x, x[-1])\n",
    "        yq = x[-1]\n",
    "        y = yq + 2 * e\n",
    "        n_iter = max_iter\n",
    "        while abs(y - yq) > e:\n",
    "            yq = x[-1]\n",
    "\n",
    "            pc, _, v = ssa(x, dim)\n",
    "            xr = inv_ssa(pc, v, k)\n",
    "\n",
    "            y = xr[-1]\n",
    "            x[-1] = y\n",
    "            n_iter -= 1\n",
    "            if n_iter <= 0:\n",
    "                print('ssa_predict> number of iterations exceeded')\n",
    "                break\n",
    "\n",
    "        xf[i] = x[-1]\n",
    "    xf = xf + mean_x\n",
    "    return xf\n",
    "\n",
    "\n",
    "def ssa_cutoff_order(x: np.ndarray, dim=200, cutoff_pctl=75, show_plot=False):\n",
    "    \"\"\"\n",
    "    Tries to find best cutoff for number of order when increment changes of informational entropy\n",
    "    becomes little and the effective information saturates.\n",
    "    :param x: series\n",
    "    :param dim: embedding dimensions (200 by default)\n",
    "    :param cutoff_pctl: percentile of changes (75%)\n",
    "    :param show_plot: true if we need to see informational curve\n",
    "    :return: cutoff number\n",
    "    \"\"\"\n",
    "    _, s, _ = ssa(x, dim)\n",
    "    curve = -s/s.sum() * np.log(s/s.sum())\n",
    "    pctl = np.percentile(curve, cutoff_pctl)\n",
    "    n_cutoff = sum(curve > pctl)\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.plot(curve)\n",
    "        plt.ylabel('Increment of Singular Entropy')\n",
    "        plt.xlabel('Number of Order')\n",
    "        plt.vlines(n_cutoff, 0, max(curve), 'g', linestyles='dotted')\n",
    "        plt.text(dim*0.6, max(curve)*0.9, 'Cutoff order: %d' % n_cutoff)\n",
    "        \n",
    "    return n_cutoff\n",
    "\n",
    "\n",
    "def ssaview(y, dim, k):\n",
    "    \"\"\"\n",
    "    Visualising tools for singular spectrum analysis\n",
    "    Example:\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>>\n",
    "    >>> x = np.linspace(0, 5, 1000)\n",
    "    >>> y = 2*x + 2*np.sin(5*x) + 0.5*np.random.randn(1000)\n",
    "    >>> ssaview(y, 15, [0,1])\n",
    "    :param y: series\n",
    "    :param dim: the embedding dimension\n",
    "    :param k: components indexes for reconstrunction\n",
    "    \"\"\"\n",
    "    pc, s, v = ssa(y, dim)\n",
    "    yr = inv_ssa(pc, v, k)\n",
    "\n",
    "    plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)\n",
    "    plt.title('Singular Spectrum View for %d window length' % dim)\n",
    "    plt.plot(y, color='#6ec0fa', lw=1.2)\n",
    "    plt.plot(yr, 'r', lw=1)\n",
    "    plt.ylabel('Series')\n",
    "    plt.legend(['Original', 'Reconstructed'])\n",
    "\n",
    "    # residuals chart\n",
    "    plt.subplot2grid((3, 3), (2, 0), colspan=2)\n",
    "    plt.plot(y - yr, 'g', lw=1)\n",
    "    plt.ylabel('Residual')\n",
    "    plt.legend(['Residual'])\n",
    "    plt.xlabel('Data points')\n",
    "\n",
    "    # resuduals qq-plot\n",
    "    plt.subplot2grid((3, 3), (0, 2), rowspan=2)\n",
    "    stats.probplot(y - yr, dist=\"norm\", plot=pylab)\n",
    "    plt.title('Residuals QQ plot')\n",
    "\n",
    "    # singular values\n",
    "    plt.subplot2grid((3, 3), (2, 2))\n",
    "    plt.title('Singular spectrum')\n",
    "    plt.plot(100 * s / s.sum(), 'g', marker='*', lw=1, alpha=0.6)\n",
    "    plt.xlabel('Eigenvalue number')\n",
    "    plt.ylabel('Eigenvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6952a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "import os.path\n",
    "import operator\n",
    "from os import system\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import wave\n",
    "import scipy as sc\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import math\n",
    "import librosa as lb\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "from itertools import product\n",
    "import datetime\n",
    "import sys\n",
    "from scipy import io\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689d5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(my_path,model):\n",
    "    wit_key = ''\n",
    "\n",
    "    AUDIO_FILE =  path.join(my_path)\n",
    "\n",
    "    # use the audio file as the audio source\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(my_path) as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "    if(model == 'google'):\n",
    "        # Google\n",
    "        try:\n",
    "            return r.recognize_google(audio)\n",
    "        except sr.UnknownValueError:\n",
    "             print(\"Google: -_-\")\n",
    "            \n",
    "        except sr.RequestError as e:\n",
    "            print(\"Google error; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9c3789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call Mom call Mom'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs, data = scipy.io.wavfile.read(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/Audio3.wav\")\n",
    "elementsInBucket = 25\n",
    "n = int(len(data)/elementsInBucket)\n",
    "\n",
    "#Breaks array into buckets of elements\n",
    "def createBuckets(arr, n):\n",
    "    length = len(arr)\n",
    "    return [ arr[i*length // n: (i+1)*length // n] \n",
    "             for i in range(n) ]\n",
    "\n",
    "#Load audio file\n",
    "arr = np.copy(data)\n",
    "#Store split array into variable\n",
    "splitArray = createBuckets(arr,n)\n",
    "\n",
    "l = list()\n",
    "\n",
    "for x in splitArray[:n]:\n",
    "    #print(np.fliplr([x])[0])\n",
    "    l.extend(np.fliplr([x])[0])\n",
    "\n",
    "data2 = np.asanyarray(l)\n",
    "\n",
    "scipy.io.wavfile.write(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/phva_demo.wav\", fs, data2)\n",
    "transcribe(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/phva_demo.wav\", \"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a560cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This attack takes in the path of the wav file\n",
    "#The time interval representation of the wav file (use scipy.io.wavfile.read)\n",
    "#The window size of the attack\n",
    "#The sample rate of the file\n",
    "def TDIAttack(path, inputArray, windowSize, fs):\n",
    "    n = int(len(inputArray)/windowSize)\n",
    "\n",
    "    #Breaks array into buckets of elements\n",
    "    #Each bucket has 'windowSize' amount of elements\n",
    "    def createBuckets(arr, n):\n",
    "        length = len(arr)\n",
    "        return [ arr[i*length // n: (i+1)*length // n] \n",
    "                 for i in range(n) ]\n",
    "\n",
    "    #Load audio file\n",
    "    arr = np.copy(inputArray)\n",
    "    \n",
    "    #Store split array into variable\n",
    "    splitArray = createBuckets(arr,n)\n",
    "\n",
    "    l = list()\n",
    "\n",
    "    for x in splitArray[:n]:\n",
    "        #print(np.fliplr([x])[0])\n",
    "        l.extend(np.fliplr([x])[0])\n",
    "    \n",
    "    #Stores the modified array and casts it as int\n",
    "    data2 = np.asanyarray(l)\n",
    "    #Ensures the file is of the right type otherwise errors occur\n",
    "    data2= np.asarray(data2,dtype=np.int16)\n",
    "    \n",
    "    #How to store the new location of the wav file\n",
    "    new_audio_path = path[0:-4]+''+str(fs)+'_TDI'+str(windowSize)+'.wav'\n",
    "    \n",
    "    return new_audio_path, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0d3a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text Mom Mom Mom'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "from os import path\n",
    "import os.path\n",
    "import operator\n",
    "from os import system\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import wave\n",
    "import scipy as sc\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import math\n",
    "import librosa as lb\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "from itertools import product\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#This function transcribes the wav file based off the specific 'model' transcription \n",
    "def transcribe(my_path,model):\n",
    "    wit_key = ''\n",
    "\n",
    "    AUDIO_FILE =  path.join(my_path)\n",
    "\n",
    "    # use the audio file as the audio source\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(my_path) as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "    if(model == 'google'):\n",
    "        # Google\n",
    "        try:\n",
    "            return r.recognize_google(audio)\n",
    "        except sr.UnknownValueError:\n",
    "             print(\"Google: -_-\")\n",
    "            \n",
    "        except sr.RequestError as e:\n",
    "            print(\"Google error; {0}\".format(e))\n",
    "    \n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "#Path of the wav file to modify \n",
    "fs, data = scipy.io.wavfile.read(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/phva_demo.wav\")\n",
    "\n",
    "#Determines the size of the window to invert \n",
    "elementsInBucket = 25\n",
    "n = int(len(data)/elementsInBucket)\n",
    "\n",
    "#Breaks array into n buckets of elements\n",
    "def createBuckets(arr, n):\n",
    "    length = len(arr)\n",
    "    return [ arr[i*length // n: (i+1)*length // n] \n",
    "             for i in range(n) ]\n",
    "\n",
    "#Load audio file\n",
    "arr = np.copy(data)\n",
    "#Store split array into variable\n",
    "splitArray = createBuckets(arr,n)\n",
    "\n",
    "l = list()\n",
    "\n",
    "for x in splitArray[:n]:\n",
    "    #print(np.fliplr([x])[0])\n",
    "    l.extend(np.fliplr([x])[0])\n",
    "\n",
    "data2 = np.asanyarray(l)\n",
    "\n",
    "#Write back the file in proper form\n",
    "scipy.io.wavfile.write(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/Audio3.wav\", fs, data2)\n",
    "transcribe(\"/Users/sahajathota/Downloads/SEN1/PRO/MID/Code/Audio3.wav\", \"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8bb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
